{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9a329fe-4667-44b2-be93-23bcd61f08be",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "This notebook demonstrates the task of summarizing a long article using Natural Language Processing (NLP) and Machine Learning (ML) techniques.\n",
    "\n",
    "### Task Overview:\n",
    "The goal of this task is to take a lengthy article or piece of text and generate a shorter, coherent summary of the key points from the original text. This process of generating summaries is known as **Text Summarization**.\n",
    "\n",
    "### Key Concepts:\n",
    "1. **Text Summarization**:\n",
    "   - The task focuses on **abstractive text summarization**, where the model not only extracts key phrases or sentences but also generates new sentences that capture the essence of the article in a shorter form.\n",
    "\n",
    "2. **BART (Bidirectional and Auto-Regressive Transformers)**:\n",
    "   - **BART** is a state-of-the-art model for NLP tasks, especially text generation tasks like summarization.\n",
    "   - **BART** combines two powerful techniques:\n",
    "     - **Bidirectional Transformers**: Like BERT, BART understands the context of words in both directions (from left to right and right to left).\n",
    "     - **Auto-Regressive Generation**: Like GPT, BART generates text one word at a time, making it capable of producing fluent and coherent summaries.\n",
    "   - **Full Form of BART**: BART stands for **Bidirectional and Auto-Regressive Transformers**.\n",
    "   - It is pre-trained on large amounts of text and can be fine-tuned for specific tasks like summarization.\n",
    "\n",
    "3. **Hugging Face Transformers**:\n",
    "   - The **Hugging Face Transformers** library provides access to a variety of pre-trained models, including BART, that can be easily used for tasks like text summarization, translation, and question answering.\n",
    "\n",
    "4. **Pre-trained Models**:\n",
    "   - We are using a **pre-trained BART model** from the Hugging Face model hub. This means we donâ€™t need to train the model from scratch, which saves a lot of time and computational resources. The model has already been trained on large text corpora to understand language patterns, making it highly effective for tasks like summarization.\n",
    "\n",
    "5. **Text Tokenization**:\n",
    "   - The input text needs to be processed (tokenized) before being fed into the model. **Tokenization** involves converting the raw text into smaller units called **tokens**, which are easier for the model to understand and work with.\n",
    "\n",
    "6. **Output Generation**:\n",
    "   - After the input text is tokenized and passed through the model, BART generates a summary of the original text. This summary will condense the content and highlight the most important information in a readable form.\n",
    "\n",
    "### Python Libraries Used:\n",
    "- **transformers**: A Python library developed by Hugging Face that provides access to various pre-trained models, including BART.\n",
    "- **torch**: A deep learning framework used for implementing machine learning models like BART.\n",
    "- **huggingface_hub**: A Python library used for managing models and datasets from the Hugging Face model hub.\n",
    "\n",
    "### Objective:\n",
    "The objective of this notebook is to demonstrate how to use a pre-trained BART model to summarize a long article (provided as input text). The output will be a concise summary that highlights the main ideas of the article, allowing users to quickly grasp the key points.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26edda4e-d2e7-4f6b-b25d-bae9bb1412d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (2.6.0+cpu)\n",
      "Requirement already satisfied: torchvision in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (0.21.0+cpu)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (2.6.0+cpu)\n",
      "Requirement already satisfied: filelock in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "543b1c5d-351a-4976-8f1c-3331a465e78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saikiran\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Original Text:\n",
      "\n",
      "The Evolution of Artificial Intelligence: Past, Present, and Future\n",
      "Introduction\n",
      "\n",
      "Artificial Intelligence (AI) has been one of the most revolutionary fields in science and technology over the last few decades. From its origins in the mid-20th century to its widespread applications in industries today, AI has transformed the way we live, work, and communicate. This article explores the evolution of AI, tracing its development from the early days to the cutting-edge advancements of the present and its future potential.\n",
      "\n",
      "The Beginnings of Artificial Intelligence\n",
      "\n",
      "The concept of artificial intelligence is older than most people realize. The roots of AI can be traced back to ancient myths and legends, where automatons and artificial beings were imagined as human-like entities. However, AI as we know it today began to take shape in the 1950s, when researchers first started developing theoretical models for machines to perform tasks requiring human intelligence.\n",
      "\n",
      "In 1956, the term \"artificial intelligence\" was coined by John McCarthy at the Dartmouth Conference, marking the formal birth of the field. Early AI research was heavily influenced by the idea that human thought could be replicated through symbolic logic and rule-based systems. Researchers at the time believed that machines could be programmed to solve problems by processing information in a way similar to the human brain.\n",
      "\n",
      "The Rise of Symbolic AI\n",
      "\n",
      "During the 1960s and 1970s, AI research primarily focused on symbolic AI. This approach revolved around representing knowledge in the form of symbols and using logical rules to manipulate those symbols. Early AI programs like ELIZA (a natural language processing program) and SHRDLU (a program that could manipulate objects in a virtual environment) demonstrated the potential of symbolic AI.\n",
      "\n",
      "However, symbolic AI faced challenges as it struggled to handle the complexity and ambiguity of the real world. These systems required exhaustive rule sets and did not perform well when faced with tasks that were not explicitly defined. Despite these challenges, the research laid important groundwork for future AI developments.\n",
      "\n",
      "The AI Winter\n",
      "\n",
      "In the 1970s and 1980s, AI research faced a setback known as the \"AI Winter.\" This period was characterized by reduced funding and interest in AI, as many of the promises of early AI research failed to materialize. The limitations of symbolic AI became evident, and researchers began to realize that replicating human intelligence through explicit rules and logic was a much harder problem than initially anticipated.\n",
      "\n",
      "However, AI did not disappear during this period. Research continued in niche areas, such as expert systems, which were designed to mimic human expertise in specific domains. Expert systems gained some success in industries like medicine, where they were used to diagnose diseases or recommend treatments.\n",
      "\n",
      "The Rise of Machine Learning\n",
      "\n",
      "In the 1990s, the field of AI experienced a resurgence with the rise of machine learning (ML), a subfield of AI that focuses on developing algorithms that allow computers to learn from data. Unlike symbolic AI, which relied on manually crafted rules, machine learning enabled computers to improve their performance through experience. Instead of being explicitly programmed with every solution, machine learning algorithms could recognize patterns and make predictions based on data.\n",
      "\n",
      "The success of machine learning was largely fueled by the increasing availability of large datasets and more powerful computing resources. Early machine learning techniques, such as decision trees and support vector machines, were effective in solving problems like image recognition, speech recognition, and natural language processing.\n",
      "\n",
      "One of the breakthrough moments for AI in the 1990s came with IBM's Deep Blue, which famously defeated world chess champion Garry Kasparov in 1997. Deep Blue's success demonstrated the power of AI when combined with machine learning and computational power.\n",
      "\n",
      "The Age of Deep Learning\n",
      "\n",
      "The real breakthrough in AI came with the development of deep learning, a subfield of machine learning that uses artificial neural networks to model complex relationships in data. Neural networks are inspired by the human brain, with layers of interconnected nodes that process information. Deep learning algorithms are capable of learning from large volumes of data, making them highly effective in tasks such as image and speech recognition, language translation, and autonomous driving.\n",
      "\n",
      "In the early 2010s, deep learning began to revolutionize the field of AI. Techniques like convolutional neural networks (CNNs) and recurrent neural networks (RNNs) enabled AI systems to achieve human-level performance in tasks like object detection and natural language understanding. For instance, in 2012, a deep learning model called AlexNet won the ImageNet competition by a large margin, demonstrating the power of deep learning for image classification.\n",
      "\n",
      "Since then, deep learning has powered many AI advancements, including voice assistants like Amazon's Alexa, Apple's Siri, and Google Assistant. These systems rely on deep learning models to understand spoken language and provide relevant responses. Deep learning has also been instrumental in the development of self-driving cars, with companies like Tesla and Waymo using AI to navigate vehicles in real-world environments.\n",
      "\n",
      "AI in the Modern World\n",
      "\n",
      "Today, AI is everywhere. It powers a wide range of applications across industries, from healthcare to finance to entertainment. AI-driven technologies like machine learning algorithms, chatbots, recommendation systems, and autonomous robots are changing the way we live and work.\n",
      "\n",
      "In healthcare, AI is being used to analyze medical images, predict patient outcomes, and personalize treatment plans. In finance, AI is used for fraud detection, algorithmic trading, and customer service. In retail, AI-driven recommendation systems help companies like Amazon and Netflix suggest products and content based on individual preferences.\n",
      "\n",
      "Moreover, the development of reinforcement learning, a type of machine learning where an AI system learns through trial and error, has opened up new possibilities. Reinforcement learning is used in areas like robotics, where machines learn to perform complex tasks through interaction with their environment.\n",
      "\n",
      "The Future of AI\n",
      "\n",
      "Looking to the future, the potential of AI seems limitless. As AI technologies continue to advance, they will play an even greater role in shaping industries and societies. Some of the exciting possibilities include:\n",
      "\n",
      "General AI (AGI): While most AI systems today are narrow in scope, general AI (AGI) refers to machines that can perform any intellectual task that a human can. Achieving AGI is still a distant goal, but researchers are making progress in developing more adaptable and intelligent systems.\n",
      "\n",
      "Ethical AI: As AI becomes more integrated into our lives, there are growing concerns about its ethical implications. Issues such as bias in AI algorithms, job displacement, and the potential for AI to be used in harmful ways need to be addressed. Researchers are increasingly focusing on developing ethical frameworks and guidelines for AI.\n",
      "\n",
      "AI and Human Collaboration: Rather than replacing humans, AI is likely to complement human abilities. In the future, AI systems could work alongside humans to enhance decision-making, creativity, and productivity. For example, AI could assist doctors in diagnosing diseases or help artists create new forms of digital art.\n",
      "\n",
      "AI in Space Exploration: AI will play a key role in the future of space exploration, from navigating spacecraft to analyzing data from distant planets. AI-powered systems could help scientists make new discoveries and explore the cosmos more efficiently.\n",
      "\n",
      "Conclusion\n",
      "\n",
      "Artificial Intelligence has come a long way since its inception, and its evolution continues to shape our world. From its early days of symbolic AI to the rise of deep learning and the widespread applications of AI today, the field has seen remarkable progress. As we look to the future, AI promises to continue transforming industries, improving our lives, and opening up new possibilities.\n",
      "\n",
      "However, with these advancements come important challenges. Ethical considerations, the impact of AI on employment, and the potential risks of AGI are all questions that need careful thought and discussion. The future of AI will require collaboration between researchers, policymakers, and the public to ensure that AI is developed and deployed in a responsible and beneficial way.\n",
      "\n",
      "As AI continues to evolve, one thing is certain: its journey is just beginning, and its impact on society will only grow in the coming years.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Summarized Text:\n",
      "Artificial Intelligence (AI) has been one of the most revolutionary fields in science and technology. From its origins in the mid-20th century to its widespread applications in industries today, AI has transformed the way we live, work, and communicate. This article explores the evolution of AI, tracing its development from the early days to the cutting-edge advancements of the present and its future potential.\n"
     ]
    }
   ],
   "source": [
    "# Install the required libraries\n",
    "!pip install transformers\n",
    "\n",
    "# Import necessary libraries\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "# Define the summarization function\n",
    "def summarize_article(input_text, max_summary_length=100):\n",
    "    \"\"\"\n",
    "    Summarizes the given input text using the BART model.\n",
    "\n",
    "    :param input_text: str, The text to summarize.\n",
    "    :param max_summary_length: int, Maximum length of the summary.\n",
    "    :return: str, The summarized text.\n",
    "    \"\"\"\n",
    "    # Load pre-trained BART model and tokenizer\n",
    "    model_name = \"facebook/bart-large-cnn\"\n",
    "    tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "    model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "    # Tokenize and encode input text\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_length=max_summary_length,\n",
    "        min_length=30,\n",
    "        length_penalty=2.0,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    # Decode and return summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "input_text = \"\"\"\n",
    "The Evolution of Artificial Intelligence: Past, Present, and Future\n",
    "Introduction\n",
    "\n",
    "Artificial Intelligence (AI) has been one of the most revolutionary fields in science and technology over the last few decades. From its origins in the mid-20th century to its widespread applications in industries today, AI has transformed the way we live, work, and communicate. This article explores the evolution of AI, tracing its development from the early days to the cutting-edge advancements of the present and its future potential.\n",
    "\n",
    "The Beginnings of Artificial Intelligence\n",
    "\n",
    "The concept of artificial intelligence is older than most people realize. The roots of AI can be traced back to ancient myths and legends, where automatons and artificial beings were imagined as human-like entities. However, AI as we know it today began to take shape in the 1950s, when researchers first started developing theoretical models for machines to perform tasks requiring human intelligence.\n",
    "\n",
    "In 1956, the term \"artificial intelligence\" was coined by John McCarthy at the Dartmouth Conference, marking the formal birth of the field. Early AI research was heavily influenced by the idea that human thought could be replicated through symbolic logic and rule-based systems. Researchers at the time believed that machines could be programmed to solve problems by processing information in a way similar to the human brain.\n",
    "\n",
    "The Rise of Symbolic AI\n",
    "\n",
    "During the 1960s and 1970s, AI research primarily focused on symbolic AI. This approach revolved around representing knowledge in the form of symbols and using logical rules to manipulate those symbols. Early AI programs like ELIZA (a natural language processing program) and SHRDLU (a program that could manipulate objects in a virtual environment) demonstrated the potential of symbolic AI.\n",
    "\n",
    "However, symbolic AI faced challenges as it struggled to handle the complexity and ambiguity of the real world. These systems required exhaustive rule sets and did not perform well when faced with tasks that were not explicitly defined. Despite these challenges, the research laid important groundwork for future AI developments.\n",
    "\n",
    "The AI Winter\n",
    "\n",
    "In the 1970s and 1980s, AI research faced a setback known as the \"AI Winter.\" This period was characterized by reduced funding and interest in AI, as many of the promises of early AI research failed to materialize. The limitations of symbolic AI became evident, and researchers began to realize that replicating human intelligence through explicit rules and logic was a much harder problem than initially anticipated.\n",
    "\n",
    "However, AI did not disappear during this period. Research continued in niche areas, such as expert systems, which were designed to mimic human expertise in specific domains. Expert systems gained some success in industries like medicine, where they were used to diagnose diseases or recommend treatments.\n",
    "\n",
    "The Rise of Machine Learning\n",
    "\n",
    "In the 1990s, the field of AI experienced a resurgence with the rise of machine learning (ML), a subfield of AI that focuses on developing algorithms that allow computers to learn from data. Unlike symbolic AI, which relied on manually crafted rules, machine learning enabled computers to improve their performance through experience. Instead of being explicitly programmed with every solution, machine learning algorithms could recognize patterns and make predictions based on data.\n",
    "\n",
    "The success of machine learning was largely fueled by the increasing availability of large datasets and more powerful computing resources. Early machine learning techniques, such as decision trees and support vector machines, were effective in solving problems like image recognition, speech recognition, and natural language processing.\n",
    "\n",
    "One of the breakthrough moments for AI in the 1990s came with IBM's Deep Blue, which famously defeated world chess champion Garry Kasparov in 1997. Deep Blue's success demonstrated the power of AI when combined with machine learning and computational power.\n",
    "\n",
    "The Age of Deep Learning\n",
    "\n",
    "The real breakthrough in AI came with the development of deep learning, a subfield of machine learning that uses artificial neural networks to model complex relationships in data. Neural networks are inspired by the human brain, with layers of interconnected nodes that process information. Deep learning algorithms are capable of learning from large volumes of data, making them highly effective in tasks such as image and speech recognition, language translation, and autonomous driving.\n",
    "\n",
    "In the early 2010s, deep learning began to revolutionize the field of AI. Techniques like convolutional neural networks (CNNs) and recurrent neural networks (RNNs) enabled AI systems to achieve human-level performance in tasks like object detection and natural language understanding. For instance, in 2012, a deep learning model called AlexNet won the ImageNet competition by a large margin, demonstrating the power of deep learning for image classification.\n",
    "\n",
    "Since then, deep learning has powered many AI advancements, including voice assistants like Amazon's Alexa, Apple's Siri, and Google Assistant. These systems rely on deep learning models to understand spoken language and provide relevant responses. Deep learning has also been instrumental in the development of self-driving cars, with companies like Tesla and Waymo using AI to navigate vehicles in real-world environments.\n",
    "\n",
    "AI in the Modern World\n",
    "\n",
    "Today, AI is everywhere. It powers a wide range of applications across industries, from healthcare to finance to entertainment. AI-driven technologies like machine learning algorithms, chatbots, recommendation systems, and autonomous robots are changing the way we live and work.\n",
    "\n",
    "In healthcare, AI is being used to analyze medical images, predict patient outcomes, and personalize treatment plans. In finance, AI is used for fraud detection, algorithmic trading, and customer service. In retail, AI-driven recommendation systems help companies like Amazon and Netflix suggest products and content based on individual preferences.\n",
    "\n",
    "Moreover, the development of reinforcement learning, a type of machine learning where an AI system learns through trial and error, has opened up new possibilities. Reinforcement learning is used in areas like robotics, where machines learn to perform complex tasks through interaction with their environment.\n",
    "\n",
    "The Future of AI\n",
    "\n",
    "Looking to the future, the potential of AI seems limitless. As AI technologies continue to advance, they will play an even greater role in shaping industries and societies. Some of the exciting possibilities include:\n",
    "\n",
    "General AI (AGI): While most AI systems today are narrow in scope, general AI (AGI) refers to machines that can perform any intellectual task that a human can. Achieving AGI is still a distant goal, but researchers are making progress in developing more adaptable and intelligent systems.\n",
    "\n",
    "Ethical AI: As AI becomes more integrated into our lives, there are growing concerns about its ethical implications. Issues such as bias in AI algorithms, job displacement, and the potential for AI to be used in harmful ways need to be addressed. Researchers are increasingly focusing on developing ethical frameworks and guidelines for AI.\n",
    "\n",
    "AI and Human Collaboration: Rather than replacing humans, AI is likely to complement human abilities. In the future, AI systems could work alongside humans to enhance decision-making, creativity, and productivity. For example, AI could assist doctors in diagnosing diseases or help artists create new forms of digital art.\n",
    "\n",
    "AI in Space Exploration: AI will play a key role in the future of space exploration, from navigating spacecraft to analyzing data from distant planets. AI-powered systems could help scientists make new discoveries and explore the cosmos more efficiently.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "Artificial Intelligence has come a long way since its inception, and its evolution continues to shape our world. From its early days of symbolic AI to the rise of deep learning and the widespread applications of AI today, the field has seen remarkable progress. As we look to the future, AI promises to continue transforming industries, improving our lives, and opening up new possibilities.\n",
    "\n",
    "However, with these advancements come important challenges. Ethical considerations, the impact of AI on employment, and the potential risks of AGI are all questions that need careful thought and discussion. The future of AI will require collaboration between researchers, policymakers, and the public to ensure that AI is developed and deployed in a responsible and beneficial way.\n",
    "\n",
    "As AI continues to evolve, one thing is certain: its journey is just beginning, and its impact on society will only grow in the coming years.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Generate and print the summary\n",
    "summary = summarize_article(input_text)\n",
    "print(\"Original Text:\")\n",
    "print(input_text)\n",
    "print(\"\\nSummarized Text:\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90964941-81fa-4e69-a53c-dc7c316f8cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862796fe-d045-4b78-b446-70b395691a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f7fadd-7022-4aa5-ba41-b54d352407f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d02aab9-1949-4f04-9f72-f8a7a4999474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e64e039-5efe-4c35-8f27-75999c28a493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98859dd1-3e73-4f40-85b5-fcdbbb687267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feabb9f-62be-4a65-a102-b3d59a0b64e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
